{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RFM Analysis\n",
    "RFM is we can say a method to analyze customer value so that we can focus on customer accordingly(We can group our customer into clusters to focus on a group having same properties similarly)\n",
    "\n",
    "RFM stands for three dimension:\n",
    "\n",
    "1)Recency: How recently did customer purchase(Duration since last purchase)\n",
    "\n",
    "2)Frequency: How often did they purchase(Total number of purchases)\n",
    "\n",
    "3)Monetary Value: How much did they spent(Total money the customer spent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"RFM Analysis with PySpark\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://Saleh-PC.yaasie.com:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>RFM Analysis with PySpark</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1cd34fa8850>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+------+------+-------------+-------+-------+--------+----+--------+\n",
      "|trans_id|account_id|  date|  type|    operation| amount|balance|k_symbol|bank| account|\n",
      "+--------+----------+------+------+-------------+-------+-------+--------+----+--------+\n",
      "|  695247|      2378|930101|PRIJEM|        VKLAD| 700.00| 700.00|    null|null|    null|\n",
      "|  171812|       576|930101|PRIJEM|        VKLAD| 900.00| 900.00|    null|null|    null|\n",
      "|  207264|       704|930101|PRIJEM|        VKLAD|1000.00|1000.00|    null|null|    null|\n",
      "| 1117247|      3818|930101|PRIJEM|        VKLAD| 600.00| 600.00|    null|null|    null|\n",
      "|  579373|      1972|930102|PRIJEM|        VKLAD| 400.00| 400.00|    null|null|    null|\n",
      "|  771035|      2632|930102|PRIJEM|        VKLAD|1100.00|1100.00|    null|null|    null|\n",
      "|  452728|      1539|930103|PRIJEM|        VKLAD| 600.00| 600.00|    null|null|    null|\n",
      "|  725751|      2484|930103|PRIJEM|        VKLAD|1100.00|1100.00|    null|null|    null|\n",
      "|  497211|      1695|930103|PRIJEM|        VKLAD| 200.00| 200.00|    null|null|    null|\n",
      "|  232960|       793|930103|PRIJEM|        VKLAD| 800.00| 800.00|    null|null|    null|\n",
      "|  505240|      1726|930103|PRIJEM|        VKLAD|1000.00|1000.00|    null|null|    null|\n",
      "|  144541|       485|930104|PRIJEM|        VKLAD| 300.00| 300.00|    null|null|    null|\n",
      "|  637741|      2177|930104|PRIJEM|        VKLAD| 800.00| 800.00|    null|null|    null|\n",
      "|  689827|      2357|930104|PRIJEM|        VKLAD| 800.00| 800.00|    null|null|    null|\n",
      "|  846006|      2881|930104|PRIJEM|        VKLAD| 700.00| 700.00|    null|null|    null|\n",
      "|  637742|      2177|930105|PRIJEM|PREVOD Z UCTU|5123.00|5923.00|  DUCHOD|  YZ|62457513|\n",
      "| 2908688|      9635|930105|PRIJEM|        VKLAD| 400.00| 400.00|    null|null|    null|\n",
      "|  232961|       793|930105|PRIJEM|PREVOD Z UCTU|3401.00|4201.00|    null|  IJ| 6149286|\n",
      "|  192096|       652|930105|PRIJEM|        VKLAD| 700.00| 700.00|    null|null|    null|\n",
      "|  542215|      1844|930106|PRIJEM|        VKLAD| 500.00| 500.00|    null|null|    null|\n",
      "+--------+----------+------+------+-------------+-------+-------+--------+----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#load dataset \n",
    "data = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"delimiter\",\";\").load(\"trans.csv\")\n",
    "\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+------+------+-------------+-------+-------+\n",
      "|trans_id|account_id|  date|  type|    operation| amount|balance|\n",
      "+--------+----------+------+------+-------------+-------+-------+\n",
      "|  695247|      2378|930101|PRIJEM|        VKLAD| 700.00| 700.00|\n",
      "|  171812|       576|930101|PRIJEM|        VKLAD| 900.00| 900.00|\n",
      "|  207264|       704|930101|PRIJEM|        VKLAD|1000.00|1000.00|\n",
      "| 1117247|      3818|930101|PRIJEM|        VKLAD| 600.00| 600.00|\n",
      "|  579373|      1972|930102|PRIJEM|        VKLAD| 400.00| 400.00|\n",
      "|  771035|      2632|930102|PRIJEM|        VKLAD|1100.00|1100.00|\n",
      "|  452728|      1539|930103|PRIJEM|        VKLAD| 600.00| 600.00|\n",
      "|  725751|      2484|930103|PRIJEM|        VKLAD|1100.00|1100.00|\n",
      "|  497211|      1695|930103|PRIJEM|        VKLAD| 200.00| 200.00|\n",
      "|  232960|       793|930103|PRIJEM|        VKLAD| 800.00| 800.00|\n",
      "|  505240|      1726|930103|PRIJEM|        VKLAD|1000.00|1000.00|\n",
      "|  144541|       485|930104|PRIJEM|        VKLAD| 300.00| 300.00|\n",
      "|  637741|      2177|930104|PRIJEM|        VKLAD| 800.00| 800.00|\n",
      "|  689827|      2357|930104|PRIJEM|        VKLAD| 800.00| 800.00|\n",
      "|  846006|      2881|930104|PRIJEM|        VKLAD| 700.00| 700.00|\n",
      "|  637742|      2177|930105|PRIJEM|PREVOD Z UCTU|5123.00|5923.00|\n",
      "| 2908688|      9635|930105|PRIJEM|        VKLAD| 400.00| 400.00|\n",
      "|  232961|       793|930105|PRIJEM|PREVOD Z UCTU|3401.00|4201.00|\n",
      "|  192096|       652|930105|PRIJEM|        VKLAD| 700.00| 700.00|\n",
      "|  542215|      1844|930106|PRIJEM|        VKLAD| 500.00| 500.00|\n",
      "+--------+----------+------+------+-------------+-------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#drop the columns that its not important and contains null\n",
    "df = data.drop('account', 'bank','k_symbol')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+-------+--------------+-----------------+-----------------+\n",
      "|summary|          trans_id|        account_id|              date|   type|     operation|           amount|          balance|\n",
      "+-------+------------------+------------------+------------------+-------+--------------+-----------------+-----------------+\n",
      "|  count|           1056320|           1056320|           1056320|1056320|        873206|          1056320|          1056320|\n",
      "|   mean|1335310.7043301272|2936.8672902150865| 965674.8198926462|   null|          null|5924.145675834605|38518.33080316599|\n",
      "| stddev|1227486.5083824112| 2477.345127182346|13945.346734698618|   null|          null| 9522.73537312024|22117.86801259184|\n",
      "|    min|                 1|                 1|            930101| PRIJEM|PREVOD NA UCET|             0.00|            -1.60|\n",
      "|    max|            999980|               998|            981231|  VYDAJ|  VYBER KARTOU|          9999.00|         99999.60|\n",
      "+-------+------------------+------------------+------------------+-------+--------------+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#see a summary of table\n",
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(trans_id,StringType,true),StructField(account_id,StringType,true),StructField(date,StringType,true),StructField(type,StringType,true),StructField(operation,StringType,true),StructField(amount,StringType,true),StructField(balance,StringType,true)))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find out the types of each column\n",
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+------+------+-------------+-------+-------+---------+\n",
      "|trans_id|account_id|  date|  type|    operation| amount|balance|full_date|\n",
      "+--------+----------+------+------+-------------+-------+-------+---------+\n",
      "|  695247|      2378|930101|PRIJEM|        VKLAD| 700.00| 700.00| 19930101|\n",
      "|  171812|       576|930101|PRIJEM|        VKLAD| 900.00| 900.00| 19930101|\n",
      "|  207264|       704|930101|PRIJEM|        VKLAD|1000.00|1000.00| 19930101|\n",
      "| 1117247|      3818|930101|PRIJEM|        VKLAD| 600.00| 600.00| 19930101|\n",
      "|  579373|      1972|930102|PRIJEM|        VKLAD| 400.00| 400.00| 19930102|\n",
      "|  771035|      2632|930102|PRIJEM|        VKLAD|1100.00|1100.00| 19930102|\n",
      "|  452728|      1539|930103|PRIJEM|        VKLAD| 600.00| 600.00| 19930103|\n",
      "|  725751|      2484|930103|PRIJEM|        VKLAD|1100.00|1100.00| 19930103|\n",
      "|  497211|      1695|930103|PRIJEM|        VKLAD| 200.00| 200.00| 19930103|\n",
      "|  232960|       793|930103|PRIJEM|        VKLAD| 800.00| 800.00| 19930103|\n",
      "|  505240|      1726|930103|PRIJEM|        VKLAD|1000.00|1000.00| 19930103|\n",
      "|  144541|       485|930104|PRIJEM|        VKLAD| 300.00| 300.00| 19930104|\n",
      "|  637741|      2177|930104|PRIJEM|        VKLAD| 800.00| 800.00| 19930104|\n",
      "|  689827|      2357|930104|PRIJEM|        VKLAD| 800.00| 800.00| 19930104|\n",
      "|  846006|      2881|930104|PRIJEM|        VKLAD| 700.00| 700.00| 19930104|\n",
      "|  637742|      2177|930105|PRIJEM|PREVOD Z UCTU|5123.00|5923.00| 19930105|\n",
      "| 2908688|      9635|930105|PRIJEM|        VKLAD| 400.00| 400.00| 19930105|\n",
      "|  232961|       793|930105|PRIJEM|PREVOD Z UCTU|3401.00|4201.00| 19930105|\n",
      "|  192096|       652|930105|PRIJEM|        VKLAD| 700.00| 700.00| 19930105|\n",
      "|  542215|      1844|930106|PRIJEM|        VKLAD| 500.00| 500.00| 19930106|\n",
      "+--------+----------+------+------+-------------+-------+-------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "full_date_var = concat(lit(\"19\"), col(\"date\"))\n",
    "full_date_func = (F.when(F.col(\"date\") == df['date'], full_date_var)\n",
    "                  .otherwise(F.col(\"date\")))\n",
    "\n",
    "df_1 = df.withColumn(\"full_date\", full_date_func)\n",
    "df_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "# convert string(date) to date(date) in new column\n",
    "df_trans = df_1.withColumn(\"new_full_date\", to_date(col(\"full_date\"), \"yyyyMMdd\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import mean, min, max, sum, datediff, to_date\n",
    "\n",
    "# compute last date for every account\n",
    "date_max = df_trans.select(max('new_full_date')).toPandas()\n",
    "\n",
    "# compute today\n",
    "current = current_date()\n",
    "\n",
    "# Calculatre Duration\n",
    "df_trans = df_trans.withColumn('Duration', datediff(lit(current), 'new_full_date'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+------+------+---------+-------+-------+---------+-------------+--------+\n",
      "|trans_id|account_id|  date|  type|operation| amount|balance|full_date|new_full_date|Duration|\n",
      "+--------+----------+------+------+---------+-------+-------+---------+-------------+--------+\n",
      "|  695247|      2378|930101|PRIJEM|    VKLAD| 700.00| 700.00| 19930101|   1993-01-01|   10343|\n",
      "|  171812|       576|930101|PRIJEM|    VKLAD| 900.00| 900.00| 19930101|   1993-01-01|   10343|\n",
      "|  207264|       704|930101|PRIJEM|    VKLAD|1000.00|1000.00| 19930101|   1993-01-01|   10343|\n",
      "| 1117247|      3818|930101|PRIJEM|    VKLAD| 600.00| 600.00| 19930101|   1993-01-01|   10343|\n",
      "|  579373|      1972|930102|PRIJEM|    VKLAD| 400.00| 400.00| 19930102|   1993-01-02|   10342|\n",
      "+--------+----------+------+------+---------+-------+-------+---------+-------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_trans.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recency = df.groupBy(\"account_id\").agg(min(\"date\").alias(\"Recency\"))\n",
    "# frequency = df.groupBy(\"account_id\",\"trans_id\").count().groupBy(\"account_id\").agg(count(\"*\").alias(\"Frequency\"))\n",
    "# # Frequency = df_trans.groupby('account_id').agg(f.count('trans_id').alias('count')) \n",
    "# monetary = df.groupBy(\"account_id\").agg(round(sum(\"amount\"), 2).alias(\"Monetary\"))\n",
    "# rfm = recency.join(frequency,\"account_id\",how =\"inner\").join(monetary,\"account_id\",how =\"inner\")\n",
    "import pyspark.sql.functions as f\n",
    "rfm_table = df_trans.groupBy(\"account_id\")\\\n",
    "                        .agg(f.count('trans_id').alias(\"Frequency\"), \\\n",
    "                             count(\"Duration\").alias(\"recency\"), \\\n",
    "                             sum(\"amount\").alias(\"Monetary\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- account_id: string (nullable = true)\n",
      " |-- Frequency: long (nullable = false)\n",
      " |-- recency: long (nullable = false)\n",
      " |-- Monetary: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfm_table.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+------------------+\n",
      "|account_id|Frequency|recency|          Monetary|\n",
      "+----------+---------+-------+------------------+\n",
      "|      4937|      560|    560| 5179029.400000004|\n",
      "|      3210|      360|    360| 3561189.000000001|\n",
      "|      2088|      348|    348|          783122.5|\n",
      "|       467|      415|    415|1493660.1999999997|\n",
      "|      1512|      337|    337|1833007.0999999994|\n",
      "+----------+---------+-------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfm_table.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_pd(df_in, columns, deciles=False):\n",
    "    if deciles:\n",
    "        percentiles = np.array(range(0, 110, 10))\n",
    "    else:\n",
    "        percentiles = [25, 50, 75]\n",
    "    percs = np.transpose([np.percentile(df_in.select(x).collect(),percentiles) for x in columns])\n",
    "    percs = pd.DataFrame(percs,columns=columns)\n",
    "    percs[\"summary\"] = [str(p) + \"%\"for p in percentiles]\n",
    "    spark_describe = df_in.describe().toPandas()\n",
    "    new_df = pd.concat([spark_describe, percs],ignore_index=True)\n",
    "    new_df = new_df.round(2)\n",
    "    return new_df[[\"summary\"] + columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = [\"Recency\",\"Frequency\",\"Monetary\"]\n",
    "# rfm.select(cols).describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(account_id='4937', Frequency=560, recency=560, Monetary=5179029.400000004, r_seg='4', f_seg='1', m_seg='1'),\n",
       " Row(account_id='3210', Frequency=360, recency=360, Monetary=3561189.000000001, r_seg='4', f_seg='1', m_seg='1'),\n",
       " Row(account_id='2088', Frequency=348, recency=348, Monetary=783122.5, r_seg='4', f_seg='1', m_seg='1'),\n",
       " Row(account_id='467', Frequency=415, recency=415, Monetary=1493660.1999999997, r_seg='4', f_seg='1', m_seg='1'),\n",
       " Row(account_id='1512', Frequency=337, recency=337, Monetary=1833007.0999999994, r_seg='4', f_seg='1', m_seg='1')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Using the quantile for defining the R,F,M values between 1 and 4\n",
    "#According to the magnitudes we have assigned values between 1 to 4 to the attributes\n",
    "\n",
    "def RScore(x):\n",
    "  #Smaller value of x(Recency) tells us that the particular customer has done some activity(like buying something or using some product) recently and contrary larger the value of x will give some inference that customer wasn't involved in activity from a long time\n",
    "  if x <= 16:\n",
    "    return 1\n",
    "  elif x<= 50:\n",
    "    return 2\n",
    "  elif x<= 143:\n",
    "    return 3\n",
    "  else:\n",
    "    return 4\n",
    "\n",
    "def FScore(x):\n",
    "  #Smaller the value of x(Frequency) tell that the customer is not involved in activities frequently and for customer with high value of x denotes that customer is involved in Frequent activities\n",
    "  if x <= 1:\n",
    "    return 4\n",
    "  elif x <= 3:\n",
    "    return 3\n",
    "  elif x <= 5:\n",
    "    return 2\n",
    "  else:\n",
    "    return 1\n",
    "\n",
    "def MScore(x):\n",
    "  #Smaller the value of x(Monetary value) tells us that customer activities cost is not much(has not spent much money on buying some product etc) and contrary higher value of x denotes that customer has spent a lot of money on activities\n",
    "  if x <= 293:\n",
    "    return 4\n",
    "  elif x <= 648:\n",
    "    return 3\n",
    "  elif x <= 1611:\n",
    "    return 2\n",
    "  else:\n",
    "    return 1\n",
    "\n",
    "#A customer can have any of the permutation of these values corresponding to their activities\n",
    "  \n",
    "\n",
    "#For each and every value of R,F,M we will pass them through the lambda function in corresponding R_udf,F_udf,M_udf\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType, DoubleType\n",
    "\n",
    "R_udf = udf(lambda x: RScore(x), StringType())\n",
    "F_udf = udf(lambda x: FScore(x), StringType())\n",
    "M_udf = udf(lambda x: MScore(x), StringType())\n",
    "\n",
    "#RFM segamentation\n",
    "from pyspark.sql.functions import concat\n",
    "\n",
    "rfm_seg=rfm_table.withColumn(\"r_seg\", R_udf(\"Recency\"))\n",
    "rfm_seg=rfm_seg.withColumn(\"f_seg\", F_udf(\"Frequency\"))\n",
    "rfm_seg=rfm_seg.withColumn(\"m_seg\", M_udf(\"Monetary\"))\n",
    "#Display is inbuilt function Databricks environment to show the dataframe\n",
    "display(rfm_seg.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(account_id='2892', Frequency=13, recency=13, Monetary=40700.0, r_seg='1', f_seg='1', m_seg='1', RFMScore='111'),\n",
       " Row(account_id='1563', Frequency=12, recency=12, Monetary=33400.0, r_seg='1', f_seg='1', m_seg='1', RFMScore='111'),\n",
       " Row(account_id='2300', Frequency=15, recency=15, Monetary=37700.0, r_seg='1', f_seg='1', m_seg='1', RFMScore='111'),\n",
       " Row(account_id='727', Frequency=11, recency=11, Monetary=35400.0, r_seg='1', f_seg='1', m_seg='1', RFMScore='111'),\n",
       " Row(account_id='869', Frequency=16, recency=16, Monetary=41300.0, r_seg='1', f_seg='1', m_seg='1', RFMScore='111')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "col_list=[\"r_seg\",\"f_seg\",\"m_seg\"]\n",
    "\n",
    "#RFM score is nothing but the concatenated R,F,M values\n",
    "rfm_seg=rfm_seg.withColumn(\"RFMScore\",concat(*col_list))\n",
    "display(rfm_seg.sort(\"RFMScore\").head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(RFMScore='111', avg(Recency)=13.0, avg(Monetary)=37169.230769230766, avg(Frequency)=13.0),\n",
       " Row(RFMScore='211', avg(Recency)=35.96551724137931, avg(Monetary)=132443.56666666665, avg(Frequency)=35.96551724137931),\n",
       " Row(RFMScore='311', avg(Recency)=101.73720136518772, avg(Monetary)=554965.3031569968, avg(Frequency)=101.73720136518772),\n",
       " Row(RFMScore='411', avg(Recency)=289.2769516728625, avg(Monetary)=1733385.512608427, avg(Frequency)=289.2769516728625)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Statistical summary for each RFM score(Mapping of RFM score against average R,F,M values)\n",
    "display(rfm_seg.groupBy(\"RFMScore\").agg({\"Recency\":\"mean\",\"Frequency\":\"mean\",\"Monetary\":\"mean\"} ).sort([\"RFMScore\"]).head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
